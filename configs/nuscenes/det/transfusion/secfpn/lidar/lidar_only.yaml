data:
  val:
    type: NuScenesDataset
    dataset_root: data/nuscenes/
    ann_file: data/nuscenes/nuscenes_infos_val.pkl
    pipeline:
      - type: LoadPointsFromFile
        coord_type: LIDAR
        load_dim: 5
        use_dim: 5
      - type: PointsRangeFilter
        point_cloud_range: [-51.2, -51.2, -5.0, 51.2, 51.2, 3.0]
      - type: DefaultFormatBundle3D
        classes: [
          'car', 'truck', 'construction_vehicle', 'bus', 'trailer',
          'barrier', 'motorcycle', 'bicycle', 'pedestrian', 'traffic_cone'
        ]
      - type: Collect3D
        keys: [points]
        meta_keys: [lidar2ego]
    modality:
      use_lidar: true
      use_camera: false
      use_map: false
      use_external: false
    test_mode: true
    box_type_3d: LiDAR
  test:
    type: NuScenesDataset
    data_root: data/nuscenes/
    ann_file: data/nuscenes/nuscenes_infos_val.pkl
    pipeline:
      - type: LoadPointsFromFile
        coord_type: LIDAR
        load_dim: 5
        use_dim: 5
      - type: PointsRangeFilter
        point_cloud_range: [-51.2, -51.2, -5.0, 51.2, 51.2, 3.0]
      - type: DefaultFormatBundle3D
      - type: Collect3D
        keys: [points]
        meta_keys: [lidar2ego]
    modality:
      use_lidar: true
      use_camera: false
      use_radar: false
      use_map: false
      use_external: false
    test_mode: true
    box_type_3d: LiDAR



# ─────────── 모델 (LiDAR Only) ───────────
model:
  type: BEVFusion
  encoders:
    lidar:
      voxelize:
        max_num_points: 10
        max_voxels: [120000, 160000]
        voxel_size: [0.1, 0.1, 0.2]
        point_cloud_range: [-51.2, -51.2, -5.0, 51.2, 51.2, 3.0]
      backbone:
        type: SparseEncoder
        in_channels: 5
        sparse_shape: [1440, 1440, 41]
        base_channels: 16
        output_channels: 128
      vtransform:
        type: BEVFormerTransform      # MMDet3D 의 BEVFormer 구현
        embed_dims: 80
        num_levels: 4
        num_heads: 8
        num_bev_layers: 3
  decoder:
    backbone:
      type: SECOND
      in_channels: 256
      layer_nums: [3, 3]
      layer_strides: [2, 2]
      out_channels: [128, 256]
    neck:
      _delete_: True
      type: TransformerFPN
      in_channels: [128, 256]      # SparseEncoder → 두 레벨 입력
      out_channels: 80
      num_outs: 2
      strides: [2, 4]
      transformer_cfg:
        embed_dims: 80
        num_layers: 1
        num_heads: 4
        feedforward_channels: 128
  fuser:
    type: IdentityFuser      # LiDAR only
    in_channels: [80]
    out_channels: 80
  heads:
    object:     
      type: TransFusionHead
      num_proposals: 200
      in_channels: 80
      hidden_channel: 128
      num_decoder_layers: 1
      num_heads: 8
      ffn_channel: 256
      dropout: 0.1
      bn_momentum: 0.1
      activation: 'relu'

      train_cfg:
        grid_size: [128, 128, 1]   #
        out_size_factor: 8
        voxel_size: [0.1, 0.1, 0.2]
        pc_range: [-51.2, -51.2, -5.0, 51.2, 51.2, 3.0]
        assigner:
          type: HungarianAssigner3D
          cls_cost:
            type: FocalLossCost
            weight: 2.0
          reg_cost:
            type: BBox3DL1Cost
            weight: 0.25

      test_cfg:
        grid_size: [128, 128, 1]   #
        out_size_factor: 8
        voxel_size: [0.1, 0.1, 0.2]
        pc_range: [-51.2, -51.2, -5.0, 51.2, 51.2, 3.0]
        nms_kernel_size: 3

      bbox_coder:
        type: TransFusionBBoxCoder
        pc_range: [-51.2, -51.2, -5.0, 51.2, 51.2, 3.0]
        score_threshold: 0.0
        out_size_factor: 8
        voxel_size: [0.1, 0.1, 0.2]

      loss_cls:
        type: FocalLoss
        use_sigmoid: true
        gamma: 2.0
        alpha: 0.25
        loss_weight: 1.0

      loss_bbox:
        type: L1Loss
        loss_weight: 0.25

      loss_heatmap:
        type: GaussianFocalLoss
        loss_weight: 1.0