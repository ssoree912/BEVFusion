# í‘œì¤€ import êµ¬ë¬¸
import torch
from mmcv import Config
from mmcv.runner import load_checkpoint
from mmdet3d.models.builder import build_detector #
from mmdet3d.datasets import build_dataloader, build_dataset

# ----------------- Attention Hook ë° ì „ì—­ ë³€ìˆ˜ -----------------

attention_maps = []

def get_attention_hook(module, input, output):
    """Swin Transformerì˜ Attention ëª¨ë“ˆì—ì„œ Attention Scoreë¥¼ ì¶”ì¶œí•˜ëŠ” Forward Hook í•¨ìˆ˜."""
    attention_maps.append(output.detach().cpu())

# ------------------------- ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜ -------------------------

def main():
    # --- ğŸ’¡ ê²½ë¡œ ì„¤ì • (ì´ ë¶€ë¶„ì„ ìˆ˜ì •í•˜ì„¸ìš”) ---
    config_path = './onfigs/nuscenes/det/centerhead/lssfpn/camera/256x704/swint/default.yaml'
    checkpoint_path = './pretrained/camera-only-det.pth'  # ì‚¬ìš©ì ì„¤ì • í•„ìš”
    gpu_id = 0
    # ---------------------------------------------

    # --- 1. ì„¤ì • íŒŒì¼ ë° ì¥ì¹˜ ì¤€ë¹„ ---
    cfg = Config.fromfile(config_path)
    device = f'cuda:{gpu_id}' if torch.cuda.is_available() else 'cpu'
    print(f"Using device: {device}")
    print(f"Loading config from: {config_path}")

    # --- 2. ëª¨ë¸ ë¹Œë“œ ë° ì²´í¬í¬ì¸íŠ¸ ë¡œë“œ ---
    cfg.model.train_cfg = None
    model = build_detector(cfg.model, test_cfg=cfg.get('test_cfg'))
    
    print(f"Loading checkpoint from: {checkpoint_path}")
    load_checkpoint(model, checkpoint_path, map_location='cpu')
    
    model.to(device)
    model.eval()
    print("Model loaded successfully.")

    # --- 3. ë°ì´í„° ë¡œë” ì¤€ë¹„ ---
    dataset = build_dataset(cfg.data.val)
    data_loader = build_dataloader(
        dataset,
        samples_per_gpu=1,
        workers_per_gpu=cfg.data.workers_per_gpu,
        dist=False,
        shuffle=False
    )
    print("Dataloader prepared.")
    
    # --- 4. ì–´í…ì…˜ ì¶”ì¶œì„ ìœ„í•œ Hook ë“±ë¡ ---
    handles = []
    camera_backbone = model.encoders.camera.backbone
    
    for stage in camera_backbone.stages:
        for block in stage.blocks:
            handle = block.attn.register_forward_hook(get_attention_hook)
            handles.append(handle)
            
    print(f"Registered {len(handles)} forward hooks in Swin Transformer blocks.")

    # --- 5. ëª¨ë¸ ì¶”ë¡  ë° Attention ì¶”ì¶œ ì‹¤í–‰ ---
    data_sample = next(iter(data_loader))
    
    for key in data_sample.keys():
        if isinstance(data_sample[key], list) and len(data_sample[key]) > 0 and isinstance(data_sample[key][0], torch.Tensor):
            for i in range(len(data_sample[key])):
                data_sample[key][i] = data_sample[key][i].to(device)

    print("\nRunning inference to trigger hooks...")
    with torch.no_grad():
        model(return_loss=False, **data_sample)

    print("Inference complete. Attention maps have been extracted.")
    
    # --- 6. Hook ì œê±° ---
    for handle in handles:
        handle.remove()
    print("All hooks have been removed.")

    # --- 7. ì¶”ì¶œëœ ê²°ê³¼ í™•ì¸ ---
    print(f"\n--- Extraction Results ---")
    print(f"Total number of attention maps extracted: {len(attention_maps)}")
    
    A_RGB_T = attention_maps
    
    for i, attn_map in enumerate(A_RGB_T):
        print(f"Map {i+1:02d} shape: {attn_map.shape}")

if __name__ == '__main__':
    main()